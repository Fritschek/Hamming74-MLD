{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYzClHPcIQgO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "G = np.array([[1, 0, 0, 0, 1, 1, 0],\n",
        "              [0, 1, 0, 0, 1, 0, 1],\n",
        "              [0, 0, 1, 0, 0, 1, 1],\n",
        "              [0, 0, 0, 1, 1, 1, 1]])\n",
        "\n",
        "def encode_and_modulate(data, G):\n",
        "    encoded = np.mod(np.dot(data, G), 2)\n",
        "    # BPSK Modulation: Map 0 -> +1, 1 -> -1\n",
        "    modulated = 1 - 2 * encoded\n",
        "    return modulated\n",
        "\n",
        "def add_noise(codewords, ebn0, rate):\n",
        "    snr_linear = 10 ** (ebn0 / 10) * rate\n",
        "    noise_std = np.sqrt(1 / (2 * snr_linear))\n",
        "    noise = noise_std * np.random.randn(*codewords.shape)\n",
        "    return codewords + noise, noise_std\n",
        "\n",
        "def mld(received, G, noise_std):\n",
        "    # Generate the codebook\n",
        "    codebook = np.array([1 - 2 * np.mod(np.dot([i >> 3, (i >> 2) & 1, (i >> 1) & 1, i & 1], G), 2) for i in range(16)])\n",
        "    decoded = []\n",
        "    for r in received:\n",
        "        # Calculate the likelihood for each codeword (considering BPSK symbols)\n",
        "        likelihoods = np.exp(-np.sum((r - codebook) ** 2, axis=1) / (2 * noise_std ** 2))\n",
        "        # Select the codeword with the highest likelihood\n",
        "        decoded.append(codebook[np.argmax(likelihoods)])\n",
        "    return np.array(decoded)\n",
        "\n",
        "def calculate_bler(original, decoded):\n",
        "    # Map back from BPSK to binary for comparison\n",
        "    decoded_binary = (1 - decoded) // 2\n",
        "    # Compare only the first 4 bits (information bits) of the original and decoded codewords\n",
        "    return np.mean(np.any(original != decoded_binary[:, :4], axis=1))\n",
        "\n",
        "def simulate_hamming_bler(ebn0_values, rate, num_blocks=1000000):\n",
        "    bler_values = []\n",
        "    for ebn0 in ebn0_values:\n",
        "        data = np.random.randint(0, 2, (num_blocks, 4))\n",
        "        encoded_data = encode_and_modulate(data, G)\n",
        "        noisy_data, noise_std = add_noise(encoded_data, ebn0, rate)\n",
        "        decoded_data = mld(noisy_data, G, noise_std)\n",
        "        bler = calculate_bler(data, decoded_data)\n",
        "        bler_values.append(bler)\n",
        "    return bler_values\n",
        "\n",
        "ebn0_values = np.arange(1, 8, .1)\n",
        "rate = 4 / 7  # Code rate\n",
        "bler_values = simulate_hamming_bler(ebn0_values, rate)\n",
        "\n",
        "# Plot the BLER vs Eb/N0\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogy(ebn0_values, bler_values, marker='o')\n",
        "plt.xlabel('$E_b/N_0$ (dB)')\n",
        "plt.ylabel('BLER')\n",
        "plt.title('BLER vs $E_b/N_0$ for Hamming (7,4) Code with MLD')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ]
}